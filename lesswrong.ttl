:life-extension rdfs:label "Life extension" .
:sens :under :life-extension ;
	rdfs:label "SENS (Strategies for Engineered Negligible Senescence)" ;
	:note "led by Aubrey de Grey" ;
	:note "Tries to reverse aging by chemical/biological interventions" ;
	:note "~$2MM rocne prijem, nema sirokou akademickou podporu, chteji porazit starnuti do 2030" .
("Calico, under Alphabet") :under :life-extension .
("If all heart disease and cancer could be cured, life expectancy would increase by merely 6-7 years.") :under :life-extension ;
	:from <http://www.nickbostrom.com/ethics/values.html> .
("More than 2/3 of 150-160 000 daily deaths die by aging.") :under :life-extension .
("stem cell treatments for parkinson's disease") :under :sens ;
	:note "treatment within 10 years?" .
("lysozomy na breakdown oxygenovaneho cholesterolu (7KC)") :under :sens ;
	:note "7-KC: arteroskleroza" .
("students: read a lot, join SRF Education") :under :sens .
("amyloid") :under :sens .

yt:pL3DW6-xzLc
	:note "Aubrey de Grey: 'give me large amounts of money'" .

:cryonics rdfs:label "Cryonics" ;
	:note "you only live twice" .
("Alcor Life Extension Foundation") :under :cryonics .
("Cryonics Institute") :under :cryonics ;
	:note "TODO: investigate" .

("Hanson hour") :under :cryonics;
	:from :petr-hudecek .

<http://thebaffler.com/salvos/everybody-freeze-pein> :under :cryonics ;
	:note "Critique of cryonics"  .
("life extension foundation") :under :cryonics ;
	:note "pretty shady" .

:xrisk-aisafety rdfs:label "X-risk and AI safety" .
<http://www.nickbostrom.com/existential/risks.html> :under :xrisk-aisafety .
("Superintelligence by Nick Bostrom") :under :xrisk-aisafety .
("Future of Humanity Institute at Oxford (Bostrom's base)") :under :xrisk-aisafety .
("Future of Life Institute") :under :xrisk-aisafety .
("Centre for Study of Existential Risk in Cambridge") :under :xrisk-aisafety .
("MIRI (Machine Intelligence Research Institute)") :under :xrisk-aisafety .
:xrisk-aisafety :note """
	Organizations aiming to develop strong AI: Google (DeepMind), IBM, GoodAI,
	OpenAI, OpenCog
""" .

("Nikolai Fyodorovich Fyodorov") :under ("Transhumanismus") ;
	:note "pre-transhumanismus (19. stoleti)" ;
	:under :zajimavosti .

("Brain Preservation Foundation") :under :cryonics .
("Institute for Science-Based Cryonics") :under :cryonics ;
	:note "plastinace" .

("nekourit; pozor na auta; pozor na nebezpecne operace; zdravou vahu; cvicit") :under :life-extension ;
	:from :petr-hudecek .

:lesswrong :todo "arguments for 'why should you care about other people?' from basics?" .

:lesswrong :note "verifikace programu je jeden z pozadavku MIRI" ;
	:note "adopt goals for instrumental reasons" ;
	:note """
	"not this again. listen, you're in a horror movie, if you split up, you die."
	going in circles => find concrete different prediction
	""" ;
	:note "attempted telekinesis" ;
	:note """
		cached selves
		consider the opposite: "what are some reasons that my initial judgement might be wrong?"
		cognitive override: notice when speaking/acting on intuitive judgement
		commitment and consistency effects: any random thing you say or do in the absence of obvious outside pressure can hijack your self-concept for the medium- to long-term future
		visualize your life as something you just inherited from someone else
		before the battle: leave a line of retreat
		during the battle: call out flinching reactions
		envision what could go badly if you come to false beliefs
	""" .

:lesswrong :note <https://web.archive.org/web/20141013084825/http://kruel.co/2013/01/07/why-you-should-be-wary-of-the-singularity-institute/> ;
	:note <https://web.archive.org/web/20141013084617/http://kruel.co/2013/01/10/the-singularity-institute-how-they-brainwash-you/> .

:lesswrong :note "think of yourself as both real and simulated" .

:lesswrong :todo "vytahnout z Jirky Nadvornika kritiku na Bostroma" .
